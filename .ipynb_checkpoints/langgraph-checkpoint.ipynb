{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da07437-1cdd-4808-9568-d5c007005576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Dict, List, Optional, Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from py2neo import Graph as Py2NeoGraph\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "# External imports from your modules\n",
    "from graph_chain import build_graph_qa_chain\n",
    "from retriever_weaviate import retriever_weaviate\n",
    "from determine_database import final_answer\n",
    "from retriever_answer_async import partial_answer_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edd51444-7a1f-4f59-ae60-f99bb3e361b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import (\n",
    "    determine_prompt,\n",
    "    recall_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517c64b7-ce14-4ad9-a6df-50ae1c583785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    question_type: Optional[str]\n",
    "    parsed_output: Dict\n",
    "    step: int\n",
    "    database: Optional[str]\n",
    "    strategy: Optional[str]\n",
    "    context_history: Dict[str, str]\n",
    "    retrieved_chunks: List[Dict]\n",
    "    sufficient: bool\n",
    "    llm: object\n",
    "    answer: Optional[str]\n",
    "    record: Optional[str]\n",
    "\n",
    "\n",
    "class QuestionAnalysis(BaseModel):\n",
    "    question_type: Literal[\"Knowledge-Type\", \"Entity-Type\", \"Mixed-Type\"]\n",
    "    database_to_call: Literal[\"Literature Text Database\", \"Literature Graph Database\", \"Both\"]\n",
    "    first_database_to_call: str\n",
    "    methods: Optional[str] = None\n",
    "    call_strategy: str\n",
    "\n",
    "\n",
    "class RecallDecision(BaseModel):\n",
    "    sufficient: bool\n",
    "    next_database: Optional[str] = None\n",
    "    reason: Optional[str] = None\n",
    "    strategy: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e66e58-9886-4e8e-9c0b-c47ea9a2b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_key = \"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\"\n",
    "wcd_url = \"https://yk7x0nnmqzuvgr8h2wu2sa.c0.asia-southeast1.gcp.weaviate.cloud\"\n",
    "wcd_api_key = \"VqrACrlTS5xlfLNY2aAjHoLEI9RVU3EPDaMt\"\n",
    "\n",
    "uri = \"neo4j+s://c0abcb56.databases.neo4j.io\"\n",
    "username = \"neo4j\"\n",
    "password = \"Vr5PhOR-n657dwRQsDfVWy_EYIE3QUUU59p7eOxJ39Q\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8d5954a-ffef-43dc-a7f4-d711a5fc0f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-58c2a9a30bf74bc0bd69688acc27c83e\"  \n",
    "\n",
    "# 替换模型初始化\n",
    "llm = ChatOpenAI(model=\"qwen-turbo-1101\",\n",
    "                base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09ab83a9-34a5-4896-84b1-782eb6cff8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_question_type(state: AgentState) -> AgentState:\n",
    "    prompt_template = ChatPromptTemplate.from_template(determine_prompt)\n",
    "    model = state['llm'].with_structured_output(QuestionAnalysis)\n",
    "    result = model.invoke(prompt_template.format_messages(question=state['question']))\n",
    "    state[\"question_type\"] = result.question_type\n",
    "    state[\"parsed_output\"] = result.dict()\n",
    "    state[\"database\"] = result.first_database_to_call if result.question_type == \"Mixed-Type\" else result.database_to_call\n",
    "    state[\"strategy\"] = result.call_strategy\n",
    "    return state\n",
    "\n",
    "\n",
    "def handle_entity_type(state: AgentState) -> AgentState:\n",
    "    graph = Py2NeoGraph(uri, auth=(\"neo4j\", password))\n",
    "    graph_qa_chain = build_graph_qa_chain(state['llm'], graph, entity_cache)\n",
    "    result = graph_qa_chain.invoke({\"question\": state[\"question\"]})\n",
    "    state[\"answer\"] = result\n",
    "    return state\n",
    "\n",
    "\n",
    "async def handle_knowledge_type(state: AgentState) -> AgentState:\n",
    "    all_result, final_response, _, _ = await partial_answer_async(\n",
    "        state[\"llm\"], state[\"question\"], wcd_url, wcd_api_key, huggingface_key\n",
    "    )\n",
    "    state[\"answer\"] = final_response\n",
    "    state[\"retrieved_chunks\"] = all_result\n",
    "    return state\n",
    "\n",
    "\n",
    "def graph_retrieval_node(state: AgentState) -> AgentState:\n",
    "    graph = Py2NeoGraph(uri, auth=(\"neo4j\", password))\n",
    "    graph_qa_chain = build_graph_qa_chain(state['llm'], graph, entity_cache)\n",
    "    result = graph_qa_chain.invoke({\"question\": f\"the entities needs to be searched{state['strategy']}\"})\n",
    "    state[\"context_history\"][f\"step {state['step']} from graph\"] = str(result)\n",
    "    state[\"retrieved_chunks\"] = result\n",
    "    return state\n",
    "\n",
    "def text_retrieval_node(state: AgentState) -> AgentState:\n",
    "    chunks = retriever_weaviate(state['strategy'], wcd_url, wcd_api_key, huggingface_key, limit=4)\n",
    "    context_list = [{'chunk': item['chunk'], 'title': item['title']} for item in chunks]\n",
    "    state[\"context_history\"][f\"step {state['step']} from text\"] = json.dumps(context_list)\n",
    "    state[\"retrieved_chunks\"] = chunks\n",
    "    return state\n",
    "\n",
    "\n",
    "def recall_decision_node(state: AgentState) -> AgentState:\n",
    "    prompt_template = ChatPromptTemplate.from_template(recall_prompt)\n",
    "    model = state['llm'].with_structured_output(RecallDecision)\n",
    "    context_str = json.dumps(state[\"context_history\"], indent=2)\n",
    "    result = model.invoke(\n",
    "        prompt_template.format_messages(\n",
    "            question=state[\"question\"],\n",
    "            context=context_str,\n",
    "            strategy=state[\"strategy\"]\n",
    "        )\n",
    "    )\n",
    "    state[\"sufficient\"] = result.sufficient\n",
    "    if not result.sufficient:\n",
    "        state[\"database\"] = result.next_database\n",
    "        state[\"strategy\"] = result.strategy\n",
    "    return state\n",
    "\n",
    "\n",
    "def final_answer_node(state: AgentState) -> AgentState:\n",
    "    state[\"answer\"] = final_answer(\n",
    "        state[\"llm\"], state[\"question\"], state[\"context_history\"], state[\"strategy\"], state.get(\"record\", \"\")\n",
    "    )\n",
    "    return state\n",
    "\n",
    "\n",
    "def route_by_question_type(state: AgentState) -> str:\n",
    "    if state[\"question_type\"] == \"Entity-Type\":\n",
    "        return \"handle_entity_type\"\n",
    "    elif state[\"question_type\"] == \"Knowledge-Type\":\n",
    "        return \"handle_knowledge_type\"\n",
    "    else:\n",
    "        return \"graph_retrieval\" if state[\"database\"] == \"Literature Graph Database\" else \"text_retrieval\"\n",
    "\n",
    "\n",
    "def route_after_recall(state: AgentState) -> str:\n",
    "    if state[\"sufficient\"]:\n",
    "        return \"final_answer\"\n",
    "    else:\n",
    "        return \"graph_retrieval\" if state[\"database\"] == \"Literature Graph Database\" else \"text_retrieval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa7dff10-7881-46cc-b159-9a52b3385769",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"entity_cache.json\"\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    entity_cache = json.load(f)\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "builder.add_node(\"determine_question_type\", determine_question_type)\n",
    "builder.add_node(\"handle_entity_type\", handle_entity_type)\n",
    "builder.add_node(\"handle_knowledge_type\", handle_knowledge_type)\n",
    "builder.add_node(\"graph_retrieval\", graph_retrieval_node)\n",
    "builder.add_node(\"text_retrieval\", text_retrieval_node)\n",
    "builder.add_node(\"recall_decision\", recall_decision_node)\n",
    "builder.add_node(\"final_answer\", final_answer_node)\n",
    "\n",
    "builder.set_entry_point(\"determine_question_type\")\n",
    "builder.add_conditional_edges(\"determine_question_type\", route_by_question_type)\n",
    "builder.add_edge(\"handle_entity_type\", END)\n",
    "builder.add_edge(\"handle_knowledge_type\", END)\n",
    "builder.add_edge(\"graph_retrieval\", \"recall_decision\")\n",
    "builder.add_edge(\"text_retrieval\", \"recall_decision\")\n",
    "builder.add_conditional_edges(\"recall_decision\", route_after_recall)\n",
    "builder.add_edge(\"final_answer\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "\n",
    "async def agent(llm, question: str, record: str = \"\"):\n",
    "    initial_state: AgentState = {\n",
    "        \"question\": question,\n",
    "        \"parsed_output\": {},\n",
    "        \"step\": 1,\n",
    "        \"database\": None,\n",
    "        \"strategy\": None,\n",
    "        \"context_history\": {},\n",
    "        \"retrieved_chunks\": [],\n",
    "        \"sufficient\": False,\n",
    "        \"llm\": llm,\n",
    "        \"record\": record,\n",
    "        \"answer\": None,\n",
    "        \"question_type\": None,\n",
    "    }\n",
    "    result = await graph.ainvoke(initial_state)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40727e6f-e479-4788-8625-d7fef610677e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.5.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from langgraph) (0.3.41)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.6.0,>=0.5.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.73-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from langgraph) (2.9.2)\n",
      "Collecting xxhash>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.1.140)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from langchain-core>=0.1->langgraph) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.12.2)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp310-cp310-win_amd64.whl.metadata (44 kB)\n",
      "Collecting langchain-core>=0.1 (from langgraph)\n",
      "  Downloading langchain_core-0.3.69-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core>=0.1->langgraph)\n",
      "  Downloading langsmith-0.4.8-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.23.4)\n",
      "Requirement already satisfied: anyio in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.6)\n",
      "Requirement already satisfied: idna in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.26.20)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.2.2)\n",
      "Downloading langgraph-0.5.3-py3-none-any.whl (143 kB)\n",
      "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl (23 kB)\n",
      "Downloading langchain_core-0.3.69-py3-none-any.whl (441 kB)\n",
      "Downloading langgraph_sdk-0.1.73-py3-none-any.whl (50 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl (30 kB)\n",
      "Downloading langsmith-0.4.8-py3-none-any.whl (367 kB)\n",
      "Downloading ormsgpack-1.10.0-cp310-cp310-win_amd64.whl (121 kB)\n",
      "Installing collected packages: xxhash, ormsgpack, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "  Attempting uninstall: xxhash\n",
      "    Found existing installation: xxhash 2.0.2\n",
      "    Uninstalling xxhash-2.0.2:\n",
      "      Successfully uninstalled xxhash-2.0.2\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.140\n",
      "    Uninstalling langsmith-0.1.140:\n",
      "      Successfully uninstalled langsmith-0.1.140\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.41\n",
      "    Uninstalling langchain-core-0.3.41:\n",
      "      Successfully uninstalled langchain-core-0.3.41\n",
      "Successfully installed langchain-core-0.3.69 langgraph-0.5.3 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.5.2 langgraph-sdk-0.1.73 langsmith-0.4.8 ormsgpack-1.10.0 xxhash-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\envs\\pytorch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\envs\\pytorch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\envs\\pytorch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\envs\\pytorch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (d:\\anaconda\\envs\\pytorch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\envs\\pytorch\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.20 requires langsmith<0.4,>=0.1.17, but you have langsmith 0.4.8 which is incompatible.\n",
      "langchain-community 0.3.5 requires langsmith<0.2.0,>=0.1.125, but you have langsmith 0.4.8 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9297697a-05af-4b1f-830a-1804a47c2299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
